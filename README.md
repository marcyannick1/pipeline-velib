# ğŸš² VÃ©lib Big Data Pipeline â€” Streaming & Batch

## ğŸ“Œ PrÃ©sentation du projet

Ce projet implÃ©mente un **pipeline Big Data complet** pour lâ€™analyse des donnÃ©es **VÃ©libâ€™ (Ãle-de-France)** en **temps rÃ©el (Streaming)** et en **historique (Batch)**.

Il couvre lâ€™ensemble de la chaÃ®ne de valeur :
- Ingestion des donnÃ©es depuis lâ€™API Open Data VÃ©lib
- Stockage distribuÃ© avec **HDFS**
- Traitement Big Data avec **Apache Spark**
- Calcul de **KPI temps rÃ©el et batch**
- Stockage analytique dans **MongoDB**
- Exposition via une **API Backend**
- Visualisation via **Frontend Web** et **Power BI**

---

## ğŸ§± Architecture globale

```
API VÃ©lib (OpenData)
        â†“
Ingestion Python (Docker)
        â†“
        HDFS
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ /velib/raw           â”‚  â† JSON bruts
 â”‚ /velib/staging       â”‚  â† Parquet nettoyÃ©
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
     Apache Spark
  â”œâ”€ spark_staging_velib.py
  â”œâ”€ spark_kpi_batch.py
  â””â”€ spark_kpi_streaming.py
        â†“
      MongoDB
        â†“
 Backend API (Node.js)
        â†“
 Frontend Web (Vite)
        â†“
     Power BI
```

---

## ğŸ“ Structure du projet

```
.
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ script/
â”‚   â”‚   â””â”€â”€ fetch_velib_api.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ spark/
â”‚   â”œâ”€â”€ spark_staging_velib.py
â”‚   â”œâ”€â”€ spark_kpi_batch.py
â”‚   â””â”€â”€ spark_kpi_streaming.py
â”‚
â”œâ”€â”€ back/
â”‚   â”œâ”€â”€ controllers/
â”‚   â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ server.js
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ front/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ powerbi/
â”‚   â”œâ”€â”€ analysis.pbix
â”‚   â”œâ”€â”€ API_ENDPOINTS_KPI.md
â”‚   â””â”€â”€ GUIDE_POWERBI_API.md
```

---

## ğŸ§© Technologies utilisÃ©es

| Composant | Technologie |
|---------|-------------|
| Ingestion | Python, Requests |
| Stockage | HDFS |
| Traitement | Apache Spark (Batch & Streaming) |
| Base analytique | MongoDB |
| Backend API | Node.js / Express |
| Frontend | Vite / JavaScript |
| BI | Power BI |
| Orchestration | Docker / Docker Compose |

---

## ğŸ”„ Pipeline de donnÃ©es

### 1ï¸âƒ£ Ingestion (temps rÃ©el)
- Script Python exÃ©cutÃ© dans un conteneur Docker
- Appel de lâ€™API VÃ©lib toutes les X secondes
- Stockage direct dans **HDFS `/velib/raw/`**

### 2ï¸âƒ£ Staging (Spark)
- Nettoyage des donnÃ©es
- Typage des colonnes
- Conversion JSON â†’ Parquet
- Sortie : **`/velib/staging/`**

### 3ï¸âƒ£ KPI Batch (Spark)
- Analyses historiques
- AgrÃ©gations journaliÃ¨res et horaires
- RÃ©sultats stockÃ©s dans :
  - MongoDB `velib_kpi_batch`

### 4ï¸âƒ£ KPI Streaming (Spark Structured Streaming)
- Calcul temps rÃ©el :
  - Totaux globaux
  - Stations pleines / vides / cassÃ©es
  - Top 10 stations
- RÃ©sultats stockÃ©s dans :
  - MongoDB `velib_kpi_streaming`

---

## ğŸ“Š KPI calculÃ©s

### ğŸ”´ Temps rÃ©el
- Nombre total de vÃ©los disponibles
- VÃ©los mÃ©caniques / Ã©lectriques
- Places libres
- Taux dâ€™occupation global
- Top 10 stations pleines
- Top 10 stations vides
- Top 10 stations Ã©lectriques
- Stations fermÃ©es
- Stations en panne
- Stations saturÃ©es
- Stations vides

### ğŸŸ¦ Batch (historique)
- DisponibilitÃ© moyenne horaire
- Taux dâ€™occupation horaire
- DisponibilitÃ© moyenne par arrondissement
- Taux dâ€™occupation moyen par arrondissement
- Arrondissements saturÃ©s / vides
- Taux dâ€™occupation journalier (min / max / avg)

---

## ğŸš€ Lancement du projet

### PrÃ©requis
- Docker
- Docker Compose

### DÃ©marrage complet
```bash
docker-compose up -d
```

### ğŸ”„ Streaming (automatique)

Le **traitement Streaming Spark** (KPI temps rÃ©el) se lance **automatiquement au dÃ©marrage des conteneurs Docker**.  
Aucune action manuelle nâ€™est requise pour le streaming.

### ğŸŸ¦ Batch (lancement manuel)

Les traitements **Batch Spark** doivent Ãªtre lancÃ©s manuellement avec les commandes suivantes.

#### 1ï¸âƒ£ GÃ©nÃ©ration du STAGING (nettoyage des donnÃ©es)
```bash
docker exec -it spark-master /spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  /opt/spark-apps/spark_staging_velib.py
```

#### 2ï¸âƒ£ Calcul des KPI Batch
```bash
docker exec -it spark-master /spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --packages org.mongodb.spark:mongo-spark-connector_2.12:10.5.0 \
  /opt/spark-apps/spark_kpi_batch.py
```

Ces traitements alimentent :
- HDFS (`/velib/staging`)
- MongoDB (`velib_kpi_batch`)

### VÃ©rification
- HDFS UI â†’ http://localhost:9870
- Spark UI â†’ http://localhost:8080
- MongoDB â†’ port 27017

---

## ğŸ“ˆ Visualisation

- **Frontend Web** : cartes et tableaux temps rÃ©el
- **Power BI** :
  - Connexion Ã  lâ€™API Backend
  - Dashboards dynamiques
  - Analyses historiques

---

## ğŸ“ Objectifs pÃ©dagogiques

- Comprendre une architecture Big Data complÃ¨te
- MaÃ®triser Spark Batch & Streaming
- Travailler avec HDFS
- Construire des KPI temps rÃ©el
- IntÃ©grer Big Data + BI

---

## ğŸ‘¤ Auteurs

Projet rÃ©alisÃ© par :

- **Yannick Coulibaly**
- **Jokast Kassa**
- **Rufus Mouakassa**
- **Serge Donou**

Master Data & IA â€” IPSSI

---
