# ğŸ“¦ LIVRAISON - MODIFICATIONS SERGE

## ğŸ“… Date: 12 dÃ©cembre 2025

## ğŸ¯ Objectif

IntÃ©gration des modifications de la branche `jokast-dev` avec adaptation des endpoints backend pour Power BI.

---

## âœ… Modifications EffectuÃ©es

### **1. Backend - API REST** ğŸ”§

- **Fichiers modifiÃ©s**:

  - `back/controllers/statsController.js` â†’ Adaptation de l'endpoint `/api/stats/arrondissement`
  - `back/routes/stats.js` â†’ Ajout de tous les endpoints stats
  - `back/server.js` â†’ Configuration serveur
  - `back/models/*` â†’ Nouveaux modÃ¨les MongoDB (ArrondissementAvgBikes, StationList, etc.)

- **Endpoints Power BI fonctionnels** (5):
  1. `http://localhost:4000/api/stats/daily-rate` â†’ Taux d'occupation journalier (1 doc)
  2. `http://localhost:4000/api/stats/hourly-rate` â†’ Taux horaire (10 docs)
  3. `http://localhost:4000/api/stats/hourly-avg-bikes` â†’ VÃ©los par heure (10 docs)
  4. `http://localhost:4000/api/stats/station-empty-full` â†’ Stations vides/pleines (1504 docs)
  5. `http://localhost:4000/api/stats/arrondissement` â†’ Stations avec noms (1932 docs)

### **2. Frontend React** ğŸ¨

- **NouveautÃ©**: Application web complÃ¨te avec Vite + React
- **Fichiers ajoutÃ©s**:
  - `front/` â†’ Toute l'application frontend
  - Dashboard interactif avec cartes, graphiques, tables
  - 50+ composants UI (shadcn/ui)

### **3. Docker** ğŸ³

- **`docker-compose.yml`** â†’ Ajout service frontend (port 5174)
- Spark workers configurÃ©s (2G RAM, 2 cores chacun)
- MongoDB healthcheck retirÃ©

### **4. Spark** âš¡

- **Fichiers modifiÃ©s**:
  - `spark/spark_kpi_batch.py` â†’ Calculs KPI batch
  - `spark/spark_kpi_streaming.py` â†’ KPI streaming en temps rÃ©el
  - `spark/spark_staging_velib.py` â†’ Staging donnÃ©es VÃ©lib
  - `spark/check_anomalies.py` â†’ DÃ©tection anomalies (nouveau)

---

## ğŸš€ Instructions pour Yannick

### **1. RÃ©cupÃ©rer les modifications**

```bash
# Option A: Merge complet
git checkout serge
git pull origin serge

# Option B: Cherry-pick commits spÃ©cifiques
git log serge --oneline -10  # Voir les commits
git cherry-pick <commit-hash>
```

### **2. DÃ©marrer l'environnement**

```bash
# DÃ©marrer tous les services
docker-compose up -d

# VÃ©rifier les services
docker ps

# Attendre 30 secondes puis lancer Spark batch
docker exec spark-master /spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --packages org.mongodb.spark:mongo-spark-connector_2.12:10.2.0 \
  /opt/spark-apps/spark_kpi_batch.py
```

### **3. AccÃ¨s aux services**

- **Backend API**: http://localhost:4000
- **Frontend React**: http://localhost:5174
- **Spark Master UI**: http://localhost:8080
- **HDFS UI**: http://localhost:9870

### **4. Tester les endpoints**

```powershell
# Test rapide de tous les endpoints
$endpoints = @(
    '/api/stats/daily-rate',
    '/api/stats/hourly-rate',
    '/api/stats/hourly-avg-bikes',
    '/api/stats/station-empty-full',
    '/api/stats/arrondissement'
)

foreach($e in $endpoints) {
    $r = Invoke-WebRequest -Uri "http://localhost:4000$e" -UseBasicParsing
    Write-Host "$e - OK" -ForegroundColor Green
}
```

---

## ğŸ“Š IntÃ©gration Power BI

### **Tables Ã  importer** (Obtenir des donnÃ©es â†’ Web):

1. **daily-rate**: `http://localhost:4000/api/stats/daily-rate`
2. **hourly-rate**: `http://localhost:4000/api/stats/hourly-rate`
3. **hourly-avg-bikes**: `http://localhost:4000/api/stats/hourly-avg-bikes`
4. **station-empty-full**: `http://localhost:4000/api/stats/station-empty-full`
5. **arrondissement**: `http://localhost:4000/api/stats/arrondissement`

### **Relation Ã  crÃ©er**:

- `arrondissement[station_id]` â†â†’ `station-empty-full[station_id]`

---

## ğŸ” DÃ©tails Techniques

### **Collections MongoDB crÃ©Ã©es**:

- `arrondissement` (1932 docs)
- `daily_rate` (1 doc)
- `hourly_rate` (10 docs)
- `hourly_avg_bikes` (10 docs)
- `station_empty_full` (1504 docs)
- `arrondissement_avg_bikes` (nouvelles collections)
- `arrondissement_rate`
- `arrondissement_empty`
- `arrondissement_full`
- `station_list`

### **ProblÃ¨mes rÃ©solus**:

- âœ… Endpoint `station-empty-full` Ã©tait 404 â†’ AjoutÃ© route + controller
- âœ… Endpoint `arrondissement` retournait donnÃ©es agrÃ©gÃ©es â†’ AdaptÃ© pour stations individuelles
- âœ… CompatibilitÃ© Power BI maintenue aprÃ¨s merge jokast-dev
- âœ… Backend redÃ©marrÃ© et testÃ©

---

## âš ï¸ Points d'attention

1. **Version Spark**: Utilise `mongo-spark-connector_2.12:10.2.0` (compatible Spark 3.3.0)
2. **Port frontend**: 5174 (Vite dev server)
3. **DonnÃ©es limitÃ©es**: Seulement heures 7-16 (collecte rÃ©cente)
4. **Anomalies connues**:
   - `max_rate = 172%` (donnÃ©es API VÃ©lib)
   - Certaines stations 100% vides (maintenance/hors service)

---

## ğŸ“ Notes

- **Branche source**: `serge` (16 commits ahead of origin/serge)
- **Merge effectuÃ©**: `jokast-dev` â†’ `serge`
- **Fichiers modifiÃ©s**: 101 fichiers
- **Tests rÃ©alisÃ©s**: Tous les endpoints testÃ©s et validÃ©s âœ…

---

## ğŸ‘¤ Contact

**Auteur**: Serge  
**Pour questions**: VÃ©rifier les commits sur `serge` branch  
**Date**: 12/12/2025

---

**Bon courage Yannick! ğŸš€**
